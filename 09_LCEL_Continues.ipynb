{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "450ee4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3479249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e086f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a curious fact about {soccer_player}.\")\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8550f57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ronaldo is known for his incredible work ethic and dedication to training. He reportedly follows a strict diet, works out daily, and even has a personal chef who travels with him to ensure he is eating the right foods.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | output_parser\n",
    "\n",
    "chain.invoke({\"soccer_player\": \"Ronaldo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec096e3f",
   "metadata": {},
   "source": [
    "* Use of `.bind()`: To add arguments to a Runnable in a LCEL Chain.\n",
    "\n",
    "For example, we can add an argument to stop the model response when it reaches the word \"Ronaldo\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3cb809a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cristiano '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model.bind(stop=[\"Ronaldo\"]) | output_parser\n",
    "\n",
    "chain.invoke({\"soccer_player\": \"Ronaldo\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04d7e9f",
   "metadata": {},
   "source": [
    "## Combining LCEL Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81592131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27146c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chamberlain was a British politician who famously pursued a policy of appeasement towards Nazi Germany in the lead up to World War II.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me a sentence about {politician}.\")\n",
    "\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "chain.invoke(\"Chamberlain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34698380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, Abraham Lincoln is widely regarded as one of the greatest presidents in American history and his leadership during the Civil War and efforts to abolish slavery have had a positive impact on humanity. His dedication to preserving the Union and commitment to equality and justice for all individuals have left a lasting legacy that continues to inspire people around the world.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combined chain\n",
    "historian_prompt = ChatPromptTemplate.from_template(\"Was {politician} positive for humanity?\")\n",
    "\n",
    "composed_chain = {\"politician\": chain} | historian_prompt | model | StrOutputParser()\n",
    "\n",
    "composed_chain.invoke({\"politician\": \"Lincoln\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8145dc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Le pays dont François Mitterrand était originaire, la France, se trouve en Europe.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another example: a chain inside another chain\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# defining manual prompts\n",
    "prompt1 = ChatPromptTemplate.from_template(\"What is the country {politician} is from?\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"What continent is the country {country} in? Respond in {language}.\"\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "chain1 = prompt1 | model | StrOutputParser()\n",
    "\n",
    "chain2 = (\n",
    "    {\"country\": chain1, \"language\": itemgetter(\"language\")}\n",
    "    | prompt2\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain2.invoke({\"politician\": \"Miterand\", \"language\": \"French\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5324082",
   "metadata": {},
   "source": [
    "## LCEL Chain at work in a typical RAG App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e09b34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6acde04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhinandansamal/anaconda3/envs/llmapp/lib/python3.11/site-packages/langchain/hub.py:86: DeprecationWarning: The `langchainhub sdk` is deprecated.\n",
      "Please use the `langsmith sdk` instead:\n",
      "  pip install langsmith\n",
      "Use the `pull_prompt` method.\n",
      "  res_dict = client.pull_repo(owner_repo_commit)\n",
      "/Users/abhinandansamal/anaconda3/envs/llmapp/lib/python3.11/site-packages/chromadb/types.py:144: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  return self.model_fields  # pydantic 2.x\n",
      "/Users/abhinandansamal/anaconda3/envs/llmapp/lib/python3.11/site-packages/chromadb/types.py:144: PydanticDeprecatedSince211: Accessing the 'model_fields' attribute on the instance is deprecated. Instead, you should access this attribute from the model class. Deprecated in Pydantic V2.11 to be removed in V3.0.\n",
      "  return self.model_fields  # pydantic 2.x\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Task Decomposition is a technique that involves breaking down complex tasks into smaller and simpler steps. This approach helps agents or models tackle difficult tasks more effectively by dividing them into manageable components. Different methods, such as Chain of Thought and Tree of Thoughts, can be used for task decomposition.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths = (\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs = dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# using prompt from the prompt hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# parallel runnable\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7ecb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
